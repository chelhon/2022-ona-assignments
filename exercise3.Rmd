---
title: "Exercise 3"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(arrow)
```

## 1. Load the files and add gender, race and tenure for examiners
### Load data

Load the following data:
  + applications from `app_data_sample.parquet`
  + edges from `edges_sample.csv`

```{r load-data}
applications <- read_parquet("app_data_sample.parquet")
edges <- read_csv("edges_sample.csv")
applications
edges
```

### Get gender for examiners

We'll get gender based on the first name of the examiner, which is recorded in the field `examiner_name_first`. We'll use library `gender` for that, relying on a modified version of their own [example](https://cran.r-project.org/web/packages/gender/vignettes/predicting-gender.html).

Note that there are over 2 million records in the applications table -- that's because there are many records for each examiner, as many as the number of applications that examiner worked on during this time frame. Our first step therefore is to get all *unique* names in a separate list `examiner_names`. We will then guess gender for each one and will join this table back to the original dataset. So, let's get names without repetition:

```{r gender-1}
library(gender)
#install_genderdata_package() # only run this line the first time you use the package, to get data for it
# get a list of first names without repetitions
examiner_names <- applications %>% 
  distinct(examiner_name_first)
examiner_names
```

Now let's use function `gender()` as shown in the example for the package to attach a gender and probability to each name and put the results into the table `examiner_names_gender`

```{r gender-2}
# get a table of names and gender
examiner_names_gender <- examiner_names %>% 
  do(results = gender(.$examiner_name_first, method = "ssa")) %>% 
  unnest(cols = c(results), keep_empty = TRUE) %>% 
  select(
    examiner_name_first = name,
    gender,
    proportion_female
  )
examiner_names_gender
```

Finally, let's join that table back to our original applications data and discard the temporary tables we have just created to reduce clutter in our environment.

```{r gender-3}
# remove extra colums from the gender table
examiner_names_gender <- examiner_names_gender %>% 
  select(examiner_name_first, gender)
# joining gender back to the dataset
applications <- applications %>% 
  left_join(examiner_names_gender, by = "examiner_name_first")
# cleaning up
rm(examiner_names)
rm(examiner_names_gender)
gc()
```


### Guess the examiner's race

We'll now use package `wru` to estimate likely race of an examiner. Just like with gender, we'll get a list of unique names first, only now we are using surnames.

```{r race-1}
library(wru)
examiner_surnames <- applications %>% 
  select(surname = examiner_name_last) %>% 
  distinct()
examiner_surnames
```
We'll follow the instructions for the package outlined here [https://github.com/kosukeimai/wru](https://github.com/kosukeimai/wru).

```{r race-2}
examiner_race <- predict_race(voter.file = examiner_surnames, surname.only = T) %>% 
  as_tibble()
examiner_race
```

As you can see, we get probabilities across five broad US Census categories: white, black, Hispanic, Asian and other. (Some of you may correctly point out that Hispanic is not a race category in the US Census, but these are the limitations of this package.)

Our final step here is to pick the race category that has the highest probability for each last name and then join the table back to the main applications table. See this example for comparing values across columns: [https://www.tidyverse.org/blog/2020/04/dplyr-1-0-0-rowwise/](https://www.tidyverse.org/blog/2020/04/dplyr-1-0-0-rowwise/). And this one for `case_when()` function: [https://dplyr.tidyverse.org/reference/case_when.html](https://dplyr.tidyverse.org/reference/case_when.html).

```{r race-3}
examiner_race <- examiner_race %>% 
  mutate(max_race_p = pmax(pred.asi, pred.bla, pred.his, pred.oth, pred.whi)) %>% 
  mutate(race = case_when(
    max_race_p == pred.asi ~ "Asian",
    max_race_p == pred.bla ~ "black",
    max_race_p == pred.his ~ "Hispanic",
    max_race_p == pred.oth ~ "other",
    max_race_p == pred.whi ~ "white",
    TRUE ~ NA_character_
  ))
examiner_race
```

Let's join the data back to the applications table.

```{r race-4}
# removing extra columns
examiner_race <- examiner_race %>% 
  select(surname,race)
applications <- applications %>% 
  left_join(examiner_race, by = c("examiner_name_last" = "surname"))
rm(examiner_race)
rm(examiner_surnames)
gc()
```


### Examiner's tenure 

To figure out the timespan for which we observe each examiner in the applications data, let's find the first and the last observed date for each examiner. We'll first get examiner IDs and application dates in a separate table, for ease of manipulation. We'll keep examiner ID (the field `examiner_id`), and earliest and latest dates for each application (`filing_date` and `appl_status_date` respectively). We'll use functions in package `lubridate` to work with date and time values.

```{r tenure-1}
library(lubridate) # to work with dates
examiner_dates <- applications %>% 
  select(examiner_id, filing_date, appl_status_date) 
examiner_dates
```

The dates look inconsistent in terms of formatting. Let's make them consistent. We'll create new variables `start_date` and `end_date`.

```{r tenure-2}
examiner_dates <- examiner_dates %>% 
  mutate(start_date = ymd(filing_date), end_date = as_date(dmy_hms(appl_status_date)))
```

Let's now identify the earliest and the latest date for each examiner and calculate the difference in days, which is their tenure in the organization.

```{r tenure-3}
examiner_dates <- examiner_dates %>% 
  group_by(examiner_id) %>% 
  summarise(
    earliest_date = min(start_date, na.rm = TRUE), 
    latest_date = max(end_date, na.rm = TRUE),
    tenure_days = interval(earliest_date, latest_date) %/% days(1)
    ) %>% 
  filter(year(latest_date)<2018)
examiner_dates
```

Joining back to the applications data.

```{r tenure-4}
applications <- applications %>% 
  left_join(examiner_dates, by = "examiner_id")
rm(examiner_dates)
gc()
```


## 2. Pick two workgroups to focus on
```{r}
# before we begin, get the workgroup from art unit as rounding down to digit tenth.
applications <- applications %>%
  mutate(wg = (applications$examiner_art_unit%/%10) * 10)

# Find out which is the dominating workgroup an examiner handled the applications for.
library(plyr)
library(dplyr)
library(lubridate)
applications <- mutate(
  applications,
  period = case_when(
    filing_date<ymd("2007-01-01") ~ NA_character_,
    filing_date<ymd("2008-01-01") ~ "t0",
    filing_date<ymd("2009-01-01") ~ "t1",
    filing_date<ymd("2010-01-01") ~ "t2",
    filing_date<ymd("2011-01-01") ~ "t3",
    filing_date<ymd("2012-01-01") ~ "t4",
    filing_date<ymd("2013-01-01") ~ "t5",
    filing_date<ymd("2014-01-01") ~ "t6",
    filing_date<ymd("2015-01-01") ~ "t7",
    filing_date<ymd("2016-01-01") ~ "t8",
    TRUE~ NA_character_)
  )

# get number of applications
library(plyr)
examiner_wg_napp <- ddply(applications, .(examiner_id, period, wg), nrow)
names(examiner_wg_napp) <- c("examiner_id","period", "wg", "n_applications")

# assume an examiner belong to the wg he/she most frequently handled applications for, if tie take the greater wg
examiner_wg_napp <- examiner_wg_napp[order(examiner_wg_napp$examiner_id, examiner_wg_napp$period, -(examiner_wg_napp$n_applications), -(examiner_wg_napp$wg)), ] ### sort first
examiner_wg <- examiner_wg_napp [!duplicated(examiner_wg_napp[c(1,2)]),]
examiner_wg <- select(examiner_wg, c("examiner_id","wg","period"))
examiner_wg <- drop_na(examiner_wg)
```

```{r}
# select the top two workgroups at t1 for our analysis, as advice dates are all in 2008
examiner_wg %>% 
  filter(period == "t1") %>% 
  count("wg") %>% 
  arrange(desc(freq)) %>%
  head(2)
```
Hence, I am selecting work groups 2450 and 2480 under the same technology centre 2400 for further analysis. 

```{r}
applications_2450 = applications[applications$wg==2450,]
applications_2480 = applications[applications$wg==2480,]
```

## How do they compare on examiners’ demographics? Show summary statistics and plots
```{r}
summary(applications_2450)
```


```{r}
summary(applications_2480)
```
5276
4232

```{r}
# reference: https://sebastiansauer.github.io/percentage_plot_ggplot2_V2/
# compare gender
library(dplyr)
library(ggplot2)
library(tidyr)
library(scales)  
library(gridExtra)

plot1 <- ggplot(applications_2450, aes(gender)) + 
          geom_bar(aes(y = (..count..)/sum(..count..))) + 
          scale_y_continuous(labels=scales::percent) +
          ylab("Relative Frequencies") +
          ylim(0,0.65) +
          ggtitle("Gender distribution for wg 2450")

plot2 <- ggplot(applications_2480, aes(gender)) + 
          geom_bar(aes(y = (..count..)/sum(..count..))) + 
          scale_y_continuous(labels=scales::percent) +
          ylim(0,0.65) +
          ylab("Relative Frequencies") +
          ggtitle("Gender distribution for wg 2480")

grid.arrange(plot1,plot2,ncol=2, widths=c(1,1))
```
Both work groups are male-dominating, with 2450 having slightly even higher imbalanced male-to-female gender ratio. 

```{r}
# compare race
plot1 <- ggplot(applications_2450, aes(race)) + 
          geom_bar(aes(y = (..count..)/sum(..count..))) + 
          scale_y_continuous(labels=scales::percent) +
          ylab("Relative Frequencies") +
          ylim(0,0.6) +
          ggtitle("Race distribution for wg 2450")

plot2 <- ggplot(applications_2480, aes(race)) + 
          geom_bar(aes(y = (..count..)/sum(..count..))) + 
          scale_y_continuous(labels=scales::percent) +
          ylab("Relative Frequencies") +
          ylim(0,0.6) +
          ggtitle("Race distribution for wg 2480")

grid.arrange(plot1,plot2,ncol=2, widths=c(1,1))
```
Both work groups are white and asian dominating, with 2450 having more asian than white and 2480 the vice vesa. 

```{r}
# compare tenure
plot1 <- ggplot(applications_2450, aes(round(tenure_days/365,digits=0))) + 
          geom_bar(aes(y = (..count..)/sum(..count..))) + 
          scale_y_continuous(labels=scales::percent) +
          ylab("Relative Frequencies") +
          xlab("Tenure (years)") +
          ylim(0,0.5) +
          ggtitle("Race distribution for wg 2450")

plot2 <- ggplot(applications_2480, aes(round(tenure_days/365,digits=0))) + 
          geom_bar(aes(y = (..count..)/sum(..count..))) + 
          scale_y_continuous(labels=scales::percent) +
          ylab("Relative Frequencies") +
          xlab("Tenure (years)") +
          ylim(0,0.5) +
          ggtitle("Race distribution for wg 2480")

grid.arrange(plot1,plot2,ncol=2, widths=c(1,1))
```
Examiners in workgroup 2450 are relatively older with USPTO with 50%+ of tenure 15+ years and a median of 16.1 years. Work group 2480 examiners are relatively younger with a median of 11.8 years in tenure.


## 3. Create advice networks and calculate centrality scores
```{r}
# subset from applications examiners who belong to the two selected work groups
examiner_aus <- applications %>%
    filter(period == "t1") %>% 
    arrange(desc(filing_date)) %>%
    filter(wg == 2450 | wg == 2480) %>%
    select(wg, examiner_art_unit, examiner_id) %>%
    distinct(examiner_id, .keep_all=TRUE) %>% 
    drop_na() #255
```

```{r}
# subset from edges examiners who belong to the two selected work groups
edges_aus <- edges %>%
  filter(ego_examiner_id %in% examiner_aus$examiner_id) %>%
  filter(alter_examiner_id %in% examiner_aus$examiner_id) %>%
  drop_na() #871

# merge work group information
network <- left_join(edges_aus, examiner_aus, by = c("ego_examiner_id" = "examiner_id"))
colnames(network)[5] <- "ego_examiner_wg"
colnames(network)[6] <- "ego_examiner_au"
network <- left_join(network, examiner_aus, by = c("alter_examiner_id" = "examiner_id"))
colnames(network)[7] <- "alter_examiner_wg"
colnames(network)[8] <- "alter_examiner_au" #871

# create edge list
edge_list <- select(network, c("ego_examiner_id","alter_examiner_id"))
```


```{r}
# create node list
ego <- select(network, c("ego_examiner_id","ego_examiner_wg","ego_examiner_au")) %>%
    dplyr::rename(id=ego_examiner_id, wg=ego_examiner_wg, au=ego_examiner_au)
alter <- select(network, c("alter_examiner_id","alter_examiner_wg","alter_examiner_au")) %>%
  dplyr::rename(id=alter_examiner_id, wg=alter_examiner_wg, au=alter_examiner_au)
nodes <- rbind(ego, alter) %>%
  distinct() %>%
  drop_na() #112

nodes
```
There are 112 distinct nodes / examiners involved in work group 2450 & 2480 applications.

```{r}
library(igraph)
advice_net = graph_from_data_frame(d=edge_list, vertices=nodes, directed=TRUE)
advice_net
```

### Different measure of centrality 
**Pick measure(s) of centrality you want to use and justify your choice**
```{r}
# Calculate Betweenness Centrality, which measures the extent to which a node lies on paths between other nodes.
V(advice_net)$dc <- degree(advice_net)
# Calculate Degree Centrality, a measure for a node in a network is just its degree, the number of edges connected to it. 
V(advice_net)$bc <- betweenness(advice_net)
# Calculate Eigenvector Centrality, which awards a number of points proportional to the centrality scores of the neighbors
V(advice_net)$ec <- evcent(advice_net)
#unlist(V(advice_net)$ec[1])
#V(advice_net)$cc <- closeness(advice_net) # dropped since closeness centrality is not well-defined for disconnected graphs
```

```{r}
data.frame(round(cbind(V(advice_net)$dc, V(advice_net)$bc, unlist(V(advice_net)$ec[1])),3))
```
Between different centralities, I would choose degree Centrality, which is a measure for the number of edges connected to a node. This is because seeking patent application is directly from one examiner to another, without leading / facilitating group communications (measured by Betweenness Centrality), reliance on certain more important persons (measured by Eigenvector Centrality), or in close network and direct relationship with mean distance (measured by Closeness Centrality). 

```{r}
# reference: https://www.data-imaginist.com/2017/ggraph-introduction-layouts/
library(ggraph)
ggraph(advice_net, layout="kk") +
  geom_edge_link()+
  geom_node_point(aes(size=dc, color=nodes$au), show.legend=T)
```
```{r}
# with labels of examiner id for further analysis
ggraph(advice_net, layout="kk") +
  geom_edge_link()+
  geom_node_point(aes(size=dc, color=nodes$au), show.legend=T) +
  geom_node_text(aes(label = nodes$id), repel=TRUE, size=2)
```

**Characterize and discuss the relationship between centrality and other examiners’ characteristics**

From the above network graph, we can observe two clear clusters of work groups 2450 and 2480 represented by dark blue and light blue respectively. In general, examiners seek advice within their own work group. Among the light blue cluster of 2480, there is one node in dark blue (75612) from 2450; conversely, among the dark blue cluster of 2450, there are two light blue nodes (e.g. 92994) from 2480. Both clusters are connected by a dark blue node (60415) and a light blue node (80925), who potentially are the only coordinators between the two work groups. Also, there are two dark blue nodes (60130, 68791) in 2450 seeking advice by themselves not connecting to any other nodes. 

Let's understand more about those examiners. 

```{r}
# examiners providing/getting advice from another work groups (75612, 92994)
network %>% filter(ego_examiner_id == 75612 | alter_examiner_id == 75612 | 
                     ego_examiner_id == 92994 | alter_examiner_id == 92994 )

applications %>% 
  filter(examiner_id==75612) # asian male from 2001

applications %>% 
  filter(examiner_id==92994) # white male from 2006

data.frame(cbind(nodes$id, nodes$wg, V(advice_net)$dc)) %>%
  dplyr::rename(id=X1,wg=X2,dc=X3) %>%
  filter(id==75612 | id==92994) #dc=3; dc=1
```

We can see that those examiners providing advice from 2450 to 2480, but not vice versa or getting advice within their own work group. They're potentially the subject matter experts who joined the wrong art unit / work group. 

```{r}
# examiners connecting the two clusters (60415, 80925)
network %>% filter(ego_examiner_id == 60415 | alter_examiner_id == 60415 | 
                     ego_examiner_id == 80925 | alter_examiner_id == 80925 )

applications %>% 
  filter(examiner_id==60415) # asian male from 2003

applications %>% 
  filter(examiner_id==80925) # asian male from 2002

data.frame(cbind(nodes$id, nodes$wg, V(advice_net)$dc)) %>%
  dplyr::rename(id=X1,wg=X2,dc=X3) %>%
  filter(id==60415 | id==80925) #dc=2; dc=3
```

The only edge joining the two work groups clusters would be formed by examiner 60415 in 2450 seeking advice from 80925 in 2480. Both of them are asian male and high tenure, relatively senior. 

```{r}
# examiners seeking advice only by themselves but not others (60130, 68791)
network %>% filter(ego_examiner_id == 60130 | alter_examiner_id == 60130 | 
                     ego_examiner_id == 68791 | alter_examiner_id == 68791 )

applications %>% 
  filter(examiner_id==60130) # black male from 2001, change tc in 2007

applications %>% 
  filter(examiner_id==68791) # white male from 2009

data.frame(cbind(nodes$id, nodes$wg, V(advice_net)$dc)) %>%
  dplyr::rename(id=X1,wg=X2,dc=X3) %>%
  filter(id==60130 | id==68791) #dc=1; dc=5
```
Examiner 68791 in work group 2450 who is relatively new only seek advice within the work group, while 68791 who has joined USPTO since 2001 (more senior perhaps) does not seek any internal/external advice (marked only himself/herself). 

Looking into the relationship between centrality and other examiners’ characteristics, we can observe that the average degree centrality (denoted by the size of nodes) for work group 2450 is higher than that of work group 2480, which means examiners in work group 2450 are more connected / proactive reaching to more examiners within their work group in seeking advice on applications. This can be explained by the fact that work group 2480 has fewer examiners.

```{r}
data.frame(cbind(nodes$id, nodes$wg, V(advice_net)$dc)) %>%
  dplyr::rename(id=X1,wg=X2,dc=X3) %>%
  group_by(wg) %>%
  dplyr::summarize(Mean=mean(dc))
```

```{r}
nodes %>% 
  filter(wg==2450) %>%
  distinct(id) %>%
  nrow()
```

```{r}
nodes %>% 
  filter(wg==2480) %>%
  distinct(id) %>%
  nrow()
```

```{r}
print(16.30526/95)
print(11.35294/17)
```


Remarks: this approach dose not take into consideration the frequency of seeking advice or the intensity of edges but the spread of connections by distinct edges. 
